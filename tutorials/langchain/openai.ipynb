{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9441304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1600b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49db3175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a category of artificial intelligence systems designed to produce content autonomously. This can include text, images, music, and even more complex outputs like entire virtual worlds or interactive applications. Unlike traditional AI systems that are typically task-specific and operate within predefined rules, generative AI leverages machine learning models to understand patterns within data and then create new, previously unseen content based on that understanding.\\n\\nA key technology underpinning many generative AI systems is the generative adversarial network (GAN), which involves two neural networksâ€”one generating content and the other evaluating it for authenticity. Other notable techniques include variational autoencoders (VAEs) and large language models like GPT (Generative Pre-trained Transformer), which are particularly well-suited for text generation.\\n\\nGenerative AI has a wide range of applications, from enhancing creative processes in art and design to automating content creation and even assisting in scientific research by generating realistic simulations of complex systems. However, it also raises important ethical and social considerations, such as the potential for misuse in creating misleading information or deep fakes.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 217, 'prompt_tokens': 13, 'total_tokens': 230, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BrRoUlZLCUHJNwKV0tSkjQeX3eeKd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f22538aa-5bb8-4eec-b082-d0f253784af5-0', usage_metadata={'input_tokens': 13, 'output_tokens': 217, 'total_tokens': 230, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e7faac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert AI Engineer. Provide me answers based on the question\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a12a792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a toolkit designed to help developers build, evaluate, and monitor applications that leverage large language models (LLMs) or generative AI. It focuses on enabling robust application development by providing features for tracing, error analysis, and the evaluation of LLM-powered applications. Some of the key benefits of using LangSmith include its ability to debug language models, track model performance, and optimize the outputs for specific use-cases by integrating seamlessly with existing workflows. By utilizing LangSmith, developers can ensure that their applications of language models are functioning as intended, identify areas for improvement, and iterate efficiently.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"Can you tell me about LangSmith?\",\n",
    "    }\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
